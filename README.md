# **TFC Vault Namespaces â€” Automated Workshop Orchestration**

*Provision user namespaces in HCP Vault using Terraform.  
Generate per-attendee credentials.  
Issue wrapped story tokens.  
Package everything for your workshop in one go.*

Â© Personal project by **Raymon Epping**.  
*Not affiliated with official HashiCorp documentation. For workshops and education purposes.*

---

## ğŸš€ What This Project Does

This repository automates an entire Vault workshop flow:

1. Convert a ticket/export **CSV â†’ JSON + extended JSON**
2. Convert JSON â†’ **Terraform tfvars** (attendees + namespace suffixes)
3. Run a **preflight check** (tools, Vault reachability, admin token)
4. Run **Terraform apply** â†’ create namespaces, auth, and policies
5. **Generate per-attendee credentials** (`.env` + CSV/JSON)
6. **Issue wrapped story tokens** (one-time, per-attendee story)
7. **Nuke all workshop namespaces safely** after the event
8. **Package everything into a zip** you can hand to participants or co-instructors

Everything is driven from a single orchestrator:

```bash
./scripts/workshop.sh
```

â¸»

ğŸ“‚ Folder Structure

```bash
tfc_vault_namespaces/
â”œâ”€â”€ main.tf
â”œâ”€â”€ providers.tf
â”œâ”€â”€ variables.tf
â”œâ”€â”€ outputs.tf
â”œâ”€â”€ versions.tf
â”œâ”€â”€ attendees.auto.tfvars.json              # <- optional, can also be generated into scripts/output/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ tickets.csv                     # <- attendee export
â”‚   â”œâ”€â”€ output/                             # <- all generated workshop files (git-ignored)
â”‚   â”‚   â”œâ”€â”€ tickets.json
â”‚   â”‚   â”œâ”€â”€ tickets_extended.json
â”‚   â”‚   â”œâ”€â”€ attendees.auto.tfvars.json
â”‚   â”‚   â”œâ”€â”€ credentials.csv
â”‚   â”‚   â”œâ”€â”€ credentials.json
â”‚   â”‚   â”œâ”€â”€ wrapped_story_tokens.csv
â”‚   â”‚   â”œâ”€â”€ wrapped_story_tokens.json
â”‚   â”‚   â””â”€â”€ *.env                           # <- per-attendee env files
â”‚   â”œâ”€â”€ convert_2_json.sh
â”‚   â”œâ”€â”€ convert_2_tfvars.sh
â”‚   â”œâ”€â”€ generate_credentials.sh
â”‚   â”œâ”€â”€ issue_wrapped_story.sh
â”‚   â”œâ”€â”€ unwrap_story.sh
â”‚   â”œâ”€â”€ login_vault.sh
â”‚   â”œâ”€â”€ workshop.sh                         # <- the orchestrator
â”‚   â”œâ”€â”€ workshop_preflight.sh
â”‚   â”œâ”€â”€ workshop_nuke_namespaces.sh
â”‚   â”œâ”€â”€ workshop_package.sh                 # <- builds workshop_package_*.zip
â”‚   â””â”€â”€ workshop_admin.sh                   # (optional helper)
â””â”€â”€ .gitignore
```

All generated workshop artefacts live in scripts/output/ and are ignored by git
(including .env, credentials.*, wrapped tokens, and generated tfvars).

â¸»

ğŸ”§ Prerequisites

You will need:
	â€¢	Terraform (v1.6+ recommended)
	â€¢	Vault CLI
	â€¢	jq
	â€¢	A running HCP Vault cluster (or Vault Enterprise with namespaces)
	â€¢	A .env file in scripts/ containing:

```bash
TF_VAR_vault_address="https://your-hcp-vault-cluster:8200"
TF_VAR_vault_admin_token="hvs.XXXXXXXX"
NUKE_ALLOWED=false
```

Only the instructor should ever set:
```bash
NUKE_ALLOWED=true
```

Attendees never need admin tokens or nuke access.

â¸»

ğŸ§ª Before You Start: Preflight

Always start with:
```bash
cd scripts
./workshop.sh preflight
```

This checks:
	â€¢	.env presence and loading
	â€¢	terraform, vault, and jq availability
	â€¢	TF_VAR_vault_address and TF_VAR_vault_admin_token
	â€¢	Vault liveness + cluster status
	â€¢	Whether the admin token can list namespaces

You get a clear green/red signal before touching Terraform.

â¸»

ğŸ§© Step 1 â€” Prepare Attendees (CSV â†’ JSON â†’ tfvars)

Put your attendee CSV at:

```bash
scripts/input/tickets.csv
```

The project supports rich exports (e.g. from event tools). A typical header might look like:

first_name;last_name;email;order.metadata.city;order.metadata.company;...

At minimum you need:
	â€¢	first_name
	â€¢	last_name
	â€¢	email
	â€¢	(optionally) order.metadata.company or similar

Then run:

```bash
cd scripts
./workshop.sh prepare tickets.csv
```

This will:
	1.	Read input/tickets.csv
	2.	Generate:
	â€¢	output/tickets.json
	â€¢	output/tickets_extended.json
	â€¢	output/attendees.auto.tfvars.json

The extended JSON and tfvars include a stable namespace_suffix, with duplicate handling:
	â€¢	raymon-e
	â€¢	raymon-b
	â€¢	etc.

This prevents collisions when you have multiple attendees with the same first name.

â¸»

â˜ ï¸ Interlude â€” When CSV Changes Break Terraform State

If you change your CSV after an initial terraform apply (for example, 
adding duplicate handling so team_raymon becomes team_raymon-e and team_raymon-b), 
Terraform might still track the old objects in state.

Typical symptoms:
	â€¢	Error: object already exists
	â€¢	Or a plan that wants to destroy/recreate the â€œwrongâ€ namespace

In that case you may need to:

```bash
terraform state list
terraform state rm module.attendees_vault["raymon-epping-at-ibm-com"]
terraform apply -auto-approve
```

Rule of thumb:

When attendee identifiers change, make sure Terraform state reflects that new reality.

The nuke command (see below) gives you an easy way to completely reset Vault-side namespaces without touching state. Use whichever path fits your workshop lifecycle.

â¸»

ğŸš€ Step 2 â€” Full Workshop Automation

Once your CSV is ready, run the full pipeline:

```bash
cd scripts
./workshop.sh full tickets.csv
```

This will:
	1.	CSV â†’ JSON (extended)
	2.	JSON â†’ attendees.auto.tfvars.json
	3.	Run preflight
	4.	Run terraform init -upgrade
	5.	Run terraform apply using output/attendees.auto.tfvars.json
	6.	Generate per-attendee credentials (generate_credentials.sh)
	7.	Issue wrapped story tokens (issue_wrapped_story.sh)

Flags:

```bash
./workshop.sh full tickets.csv --skip-tf      # skip preflight + terraform
./workshop.sh full tickets.csv --skip-creds  # skip credentials generation
./workshop.sh full tickets.csv --skip-wrap   # skip wrapped story tokens
```

End result in scripts/output/:
	â€¢	attendees.auto.tfvars.json
	â€¢	credentials.csv
	â€¢	credentials.json
	â€¢	wrapped_story_tokens.csv
	â€¢	wrapped_story_tokens.json
	â€¢	One *.env file per attendee

â¸»

ğŸ“¦ Step 3 â€” Build a Shareable Workshop Package

Instead of manually zipping things, use the package helper:

```bash
cd scripts
./workshop.sh package
```

This:
	â€¢	Collects all attendee .env files from output/
	â€¢	Includes:
	â€¢	output/credentials.csv
	â€¢	output/wrapped_story_tokens.csv
	â€¢	output/attendees.auto.tfvars.json
	â€¢	input/tickets.csv
	â€¢	Stages them into a temporary structure:
	â€¢	env/ â†’ per-attendee .env
	â€¢	meta/ â†’ credentials.csv, wrapped_story_tokens.csv
	â€¢	tfvars/ â†’ attendees.auto.tfvars.json
	â€¢	input/ â†’ tickets.csv
	â€¢	Creates a timestamped zip in scripts/, e.g.:

workshop_package_20251116_133143.zip

You can hand this archive to:
	â€¢	Co-instructors
	â€¢	Yourself on another machine
	â€¢	A workshop host who will distribute the .env files

â¸»

ğŸ Step 4 â€” Hand Out Credentials

After full or generate_credentials.sh has run, each participant gets:
	â€¢	Their personal .env file (from scripts/output/)
	â€¢	(Optionally) Their row in wrapped_story_tokens.csv or a copy of their token

Instructor flow for handing off:
	1.	Extract the zip (or copy from output/).
	2.	Give each attendee their <name>.env file and, optionally, their wrapped token.

â¸»

ğŸ”‘ Step 5 â€” Attendees Log Into Vault

From the scripts directory, an attendee can log in with:

```bash
./login_vault.sh raymon-e.env
```

This script:
	â€¢	Loads the .env
	â€¢	Sets VAULT_ADDR and VAULT_NAMESPACE
	â€¢	Uses VAULT_USERNAME / VAULT_PASSWORD with userpass auth
	â€¢	Stores the token in the Vault CLI token helper
	â€¢	Prints only safe metadata

Short version of the flow:

```bash
ğŸ“¦ Loading environment from raymon-e.env
ğŸ” Logging into Vault...

VAULT_ADDR     = https://...
VAULT_NAMESPACE= admin/team_raymon-e
VAULT_USERNAME = raymon

Password (will be hidden):
...
âœ… Logged into Vault successfully.
ğŸ’¡ Next time: source raymon-e.env && ./login_vault.sh
```

From that point on, vault CLI commands automatically use the stored token.

â¸»

ğŸ« Step 6 â€” Unwrap the Story Token

Each attendee receives a wrapped story token. They can unwrap it with either:

Direct vault CLI + jq:

```bash
vault unwrap -format=json "$WRAPPED_TOKEN" | jq '.data'
```

Or using the helper script:

```bash
./unwrap_story.sh hvs.CAESI...
```

This will:
	â€¢	Call vault unwrap
	â€¢	Show the payload (e.g. name, email, and a personal message)
	â€¢	Fail safely if the token is already used or expired

This makes the â€œsecret storyâ€ part of the workshop repeatable and easy to demo.

â¸»

ğŸ’£ Step 7 â€” Safe Nuke (After the Workshop)

When the workshop is over, you can safely delete all team_* namespaces in Vault without touching Terraform state.

Dry run:

```bash
./workshop.sh nuke --dry-run
```

Actual deletion (including orphans under admin/):

```bash
./workshop.sh nuke --include-orphans
```

Guardrails:
	â€¢	Requires NUKE_ALLOWED=true in scripts/.env
	â€¢	Prints a clear plan of which namespaces will be deleted
	â€¢	Asks you to type:

YES_NUKE_WORKSHOP

	â€¢	Deletes via Vault API (sys/namespaces/...)
	â€¢	Does not modify or delete Terraform state

Namespaces like:

```bash
admin/team_cojan
admin/team_jorg
admin/team_mahil
...
```

are removed, leaving Vault clean for the next run.

â¸»

ğŸ“Š Status Overview â€” Your Mini Dashboard

At any time, you can run:

```bash
./workshop.sh status
```

This shows:
	â€¢	Input
	â€¢	Whether input/tickets.csv exists
	â€¢	Number of attendee rows
	â€¢	Output
	â€¢	Presence/absence of:
	â€¢	tickets.json
	â€¢	tickets_extended.json
	â€¢	attendees.auto.tfvars.json
	â€¢	credentials.*
	â€¢	wrapped_story_tokens.*
	â€¢	Counts (attendees, credentials, wrapped tokens)
	â€¢	Vault
	â€¢	Reachability check
	â€¢	Namespace count
	â€¢	Names (if small)
	â€¢	Extra hint when no team_* namespaces exist:

â„¹ï¸  ğŸ§¹ No team_* namespaces found â€” Vault looks freshly nuked.



This is your quick health view during workshop prep and after cleanup.

â¸»

ğŸ›¡ï¸ Safety & Guardrails

This repo is intentionally designed to avoid â€œoopsâ€ moments:
	â€¢	nuke is instructor-only (NUKE_ALLOWED=true + confirmation phrase)
	â€¢	No admin tokens are ever written to attendee outputs
	â€¢	Per-attendee .env files are git-ignored
	â€¢	All generated artefacts live under scripts/output/
	â€¢	Terraform input is driven by generated attendees.auto.tfvars.json

You get:
	â€¢	Safe iteration while developing the workshop
	â€¢	Clean reset paths
	â€¢	Minimal blast radius if something goes wrong

â¸»

ğŸ§© Extending This Repo

You can extend this foundation with:
	â€¢	Extra attendee metadata (roles, tracks, time slots)
	â€¢	Dynamic policy templates per group or role
	â€¢	Boundary target + credential brokering per namespace
	â€¢	OpenShift / OIDC onboarding flows
	â€¢	Terraform Cloud workspace creation per team
	â€¢	Additional story layers in the wrapped payload

The current structure is modular enough that you can plug new steps into the same orchestrator (workshop.sh) without breaking existing flows.

â¸»

ğŸ¤ Credits
	â€¢	Original inspiration: Cojanâ€™s Terraform user/team creation prototype
	â€¢	Extended, automated, and turned into a workshop engine by Raymon Epping

â¸»

ğŸ§  Final Notes

This repository is built for real workshops, not slideware:
	â€¢	Short commands
	â€¢	Clear feedback
	â€¢	Safe teardown
	â€¢	Easy packaging and sharing

Use it as-is, or treat it as a starting point for your own internal training pipeline.

If you fork it, break it, or improve it â€” thatâ€™s exactly what itâ€™s here for.
